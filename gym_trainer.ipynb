{
 "cells": [
  {
   "cell_type": "code",
   "id": "d532b5cbd068e0fd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T07:25:17.090053Z",
     "start_time": "2024-04-20T07:25:12.677800Z"
    }
   },
   "source": [
    "import datetime\n",
    "\n",
    "import ray\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True, num_gpus=1, _metrics_export_port=8080, include_dashboard=True,\n",
    "         configure_logging=False)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.9.13', ray_version='2.9.1', ray_commit='cfbf98c315cfb2710c56039a3c96477d196de049', protocol_version=None)"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d044dc5047fa4fb68bd30609813deb1f"
      },
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.9.13</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.9.1</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T07:25:19.553835Z",
     "start_time": "2024-04-20T07:25:18.612975Z"
    }
   },
   "source": [
    "from minigrid.wrappers import FlatObsWrapper\n",
    "\n",
    "\n",
    "class CustomFlatObsWrapper(FlatObsWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.9.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "c39813b6e1e21314",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T07:25:22.804494Z",
     "start_time": "2024-04-20T07:25:22.784269Z"
    }
   },
   "source": [
    "from gymnasium.envs.registration import register\n",
    "\n",
    "try:\n",
    "    import gymnasium as gym\n",
    "\n",
    "    gymnasium = True\n",
    "except Exception:\n",
    "    import gym\n",
    "\n",
    "    gymnasium = False\n",
    "\n",
    "ENV_ID = \"MiniGrid-CustomMultiRoom-N6-v0\"\n",
    "\n",
    "# Register the custom environment\n",
    "register(\n",
    "    id=ENV_ID,\n",
    "    entry_point='custom_env:CustomMultiRoomEnv',\n",
    "    max_episode_steps=1000,\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "from custom_env import CustomMultiRoomEnv\n",
    "\n",
    "try:\n",
    "    import gymnasium as gym\n",
    "\n",
    "    gymnasium = True\n",
    "except Exception:\n",
    "    import gym\n",
    "\n",
    "    gymnasium = False\n",
    "from ray.tune import register_env\n",
    "\n",
    "\n",
    "def env_creator(env_config=None):\n",
    "    config = {\n",
    "        \"agent_start_pos\": (1, 1),\n",
    "        \"agent_start_dir\": 0,\n",
    "        \"goal_pos\": (15, 15),\n",
    "        \"minNumRooms\": 2,\n",
    "        \"maxNumRooms\": 5,\n",
    "        \"enable_dowham\": True,\n",
    "        \"max_episode_steps\": 1000,\n",
    "        **env_config\n",
    "    }\n",
    "    env = CustomMultiRoomEnv(**config)\n",
    "    env.reset()\n",
    "    env = CustomFlatObsWrapper(env)\n",
    "    return env\n",
    "\n",
    "\n",
    "# Register the custom environment\n",
    "register_env(\"my_minigrid_env\", env_creator)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T07:25:28.913508Z",
     "start_time": "2024-04-20T07:25:26.824468Z"
    }
   },
   "id": "a02342de972a0d02",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "from ray.rllib import BaseEnv, Policy\n",
    "from typing import Dict, Union, Optional\n",
    "from ray.rllib import BaseEnv, Policy\n",
    "from ray.rllib.evaluation import Episode\n",
    "from ray.rllib.evaluation.episode_v2 import EpisodeV2\n",
    "from ray.rllib.utils.typing import PolicyID\n",
    "\n",
    "\n",
    "class AccuracyCallback(DefaultCallbacks):\n",
    "    def on_episode_end(\n",
    "            self,\n",
    "            *,\n",
    "            worker: \"RolloutWorker\",\n",
    "            base_env: BaseEnv,\n",
    "            policies: Dict[PolicyID, Policy],\n",
    "            episode: Union[Episode, EpisodeV2, Exception],\n",
    "            env_index: Optional[int] = None,\n",
    "            **kwargs,\n",
    "    ) -> None:\n",
    "        super(DefaultCallbacks, self).on_episode_end(worker=worker, base_env=base_env,\n",
    "                                                     policies=policies, episode=episode,\n",
    "                                                     env_index=env_index, **kwargs)\n",
    "\n",
    "        episode.custom_metrics[\"mean_accuracy\"] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T07:25:37.938240Z",
     "start_time": "2024-04-20T07:25:30.538393Z"
    }
   },
   "id": "b73a400fce6e16a5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "c852061bac484afd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T07:25:37.953876Z",
     "start_time": "2024-04-20T07:25:37.938240Z"
    }
   },
   "source": [
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "from ray.air import RunConfig\n",
    "from ray import train\n",
    "\n",
    "tune_config = DQNConfig().environment(\"my_minigrid_env\").rollouts(\n",
    "    num_envs_per_worker=20,\n",
    "    observation_filter=\"MeanStdFilter\",\n",
    "    num_rollout_workers=0,\n",
    ").exploration(\n",
    "    explore=True,\n",
    "    exploration_config={\n",
    "        \"type\": \"EpsilonGreedy\",\n",
    "        \"initial_epsilon\": 1.0,\n",
    "        \"final_epsilon\": 0.1,\n",
    "        \"epsilon_timesteps\": 10000,\n",
    "    }\n",
    ").training()\n",
    "\n",
    "tune_config_dict = tune_config.to_dict()\n",
    "# Example stop criteria for MiniGrid-MultiRoom-N6-v0\n",
    "stop = {\n",
    "    \"training_iteration\": 10000,  # Increase the number of training iterations to give the agent more time to learn\n",
    "    \"timesteps_total\": 5000000,  # Increase the total number of steps to allow the agent to gather more experience\n",
    "    # \"time_total_s\": 36000,  # Uncomment and set a maximum training time in seconds if you have a time constraint\n",
    "}\n",
    "# Setup your RunConfig\n",
    "run_config = RunConfig(\n",
    "    name=\"new_experiment\",\n",
    "    stop=stop,\n",
    "    storage_path=\"C:\\\\Users\\\\BerkayEren\\\\PycharmProjects\\\\rl-learning\\\\ray_results\",\n",
    "    checkpoint_config=train.CheckpointConfig(\n",
    "        checkpoint_score_attribute=\"mean_accuracy\",\n",
    "        num_to_keep=5,\n",
    "    ),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "from ray.tune import register_env\n",
    "\n",
    "# Register the custom environment\n",
    "register_env(\"my_minigrid_env\", env_creator)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    \"DQN\",\n",
    "    param_space={\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),\n",
    "        \"momentum\": tune.grid_search([0.8, 0.9, 0.99]),\n",
    "        \"should_checkpoint\": True,\n",
    "        \"callbacks\": AccuracyCallback,\n",
    "        **tune_config\n",
    "    },\n",
    "    run_config=train.RunConfig(\n",
    "        name=\"new_experiment\",\n",
    "        stop=stop,\n",
    "        checkpoint_config=train.CheckpointConfig(\n",
    "            num_to_keep=5,\n",
    "            checkpoint_at_end=True,\n",
    "            checkpoint_frequency=50\n",
    "        ),\n",
    "        storage_path=\"C:\\\\Users\\\\BerkayEren\\\\PycharmProjects\\\\rl-learning\\\\ray_results\",\n",
    "    ),\n",
    "    tune_config=tune.TuneConfig(mode=\"max\", metric=\"episode_reward_mean\", num_samples=2, scheduler=ASHAScheduler(), ),\n",
    "\n",
    ")\n",
    "# Start the tuning process\n",
    "result = tuner.fit()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1973268c6e5e126",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "best_result = result.get_best_result(\"episode_reward_mean\", mode=\"max\")\n",
    "with best_result.checkpoint.as_directory() as checkpoint_dir:\n",
    "    print(checkpoint_dir)\n",
    "\n"
   ],
   "id": "3c1cc6c49a2debd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T10:03:04.753083Z",
     "start_time": "2024-04-20T07:25:40.738907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ray.rllib.algorithms import DQN\n",
    "from ray.tune.logger import pretty_print\n",
    "import numpy as np\n",
    "\n",
    "best_result_path = \"C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/new_experiment/DQN_my_minigrid_env_f93a7_00003_3_momentum=0.8000_2024-04-19_21-31-01/checkpoint_000001\"\n",
    "best_result_path = \"C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\"\n",
    "trainer = DQN(config=tune_config_dict)\n",
    "trainer.restore(best_result_path)\n",
    "\n",
    "for trial in range(1000):\n",
    "    print(f\"Running trial {trial + 1}\")\n",
    "    result = trainer.train()\n",
    "\n",
    "    # Save the trainer every 50 trials\n",
    "    if (trial + 1) % 50 == 0:\n",
    "        checkpoint_path = trainer.save(\n",
    "            \"C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\")\n",
    "        print(f\"Saved checkpoint to: {checkpoint_path.checkpoint.path}\")\n",
    "\n",
    "print(pretty_print(result))\n",
    "\n",
    "# best_result = result.get_best_result()\n",
    "# print(best_result)\n",
    "# best_checkpoint = best_result.get_best_checkpoint('episode_reward_mean', 'max')\n",
    "# \n",
    "# trainer = DQN(config=tune_config_dict)\n",
    "# # You can now restore your trainer from this checkpoint as shown previously\n",
    "# trainer.restore(best_checkpoint)\n",
    "\n",
    "# Initialize a list to store the observations from each trial\n",
    "all_observations = []\n",
    "\n",
    "for trial in range(10):\n",
    "    print(f\"Running trial {trial + 1}\")\n",
    "    env = env_creator({\"render_mode\": \"human\"})\n",
    "    observation, info = env.reset()\n",
    "    done = False\n",
    "    action = None\n",
    "    reward = 0\n",
    "\n",
    "    visited_states = {}\n",
    "\n",
    "    while not done:\n",
    "        # Compute the action using the trained policy\n",
    "        action = trainer.compute_single_action(observation=observation, prev_action=action, prev_reward=reward)\n",
    "\n",
    "        # Take the action in the environment\n",
    "        observation, reward, done, info, _ = env.step(action)\n",
    "\n",
    "        visited_states.setdefault(env.agent_pos, 0)\n",
    "        visited_states[env.agent_pos] += 1\n",
    "\n",
    "        # Render the environment\n",
    "        env.render()\n",
    "\n",
    "    all_observations.append(visited_states)\n"
   ],
   "id": "3d66ad92eadd6791",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 10:25:40,750\tWARNING deprecation.py:50 -- DeprecationWarning: `rllib/algorithms/simple_q/` has been deprecated. Use `rllib_contrib/simple_q/` instead. This will raise an error in the future!\n",
      "C:\\Users\\BerkayEren\\PycharmProjects\\rl-learning\\worker_env\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:483: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "C:\\Users\\BerkayEren\\PycharmProjects\\rl-learning\\worker_env\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "C:\\Users\\BerkayEren\\PycharmProjects\\rl-learning\\worker_env\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "C:\\Users\\BerkayEren\\PycharmProjects\\rl-learning\\worker_env\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-04-20 10:25:40,836\tWARNING env.py:162 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "2024-04-20 10:25:42,711\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
      "2024-04-20 10:25:42,732\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 1\n",
      "Running trial 2\n",
      "Running trial 3\n",
      "Running trial 4\n",
      "Running trial 5\n",
      "Running trial 6\n",
      "Running trial 7\n",
      "Running trial 8\n",
      "Running trial 9\n",
      "Running trial 10\n",
      "Running trial 11\n",
      "Running trial 12\n",
      "Running trial 13\n",
      "Running trial 14\n",
      "Running trial 15\n",
      "Running trial 16\n",
      "Running trial 17\n",
      "Running trial 18\n",
      "Running trial 19\n",
      "Running trial 20\n",
      "Running trial 21\n",
      "Running trial 22\n",
      "Running trial 23\n",
      "Running trial 24\n",
      "Running trial 25\n",
      "Running trial 26\n",
      "Running trial 27\n",
      "Running trial 28\n",
      "Running trial 29\n",
      "Running trial 30\n",
      "Running trial 31\n",
      "Running trial 32\n",
      "Running trial 33\n",
      "Running trial 34\n",
      "Running trial 35\n",
      "Running trial 36\n",
      "Running trial 37\n",
      "Running trial 38\n",
      "Running trial 39\n",
      "Running trial 40\n",
      "Running trial 41\n",
      "Running trial 42\n",
      "Running trial 43\n",
      "Running trial 44\n",
      "Running trial 45\n",
      "Running trial 46\n",
      "Running trial 47\n",
      "Running trial 48\n",
      "Running trial 49\n",
      "Running trial 50\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 51\n",
      "Running trial 52\n",
      "Running trial 53\n",
      "Running trial 54\n",
      "Running trial 55\n",
      "Running trial 56\n",
      "Running trial 57\n",
      "Running trial 58\n",
      "Running trial 59\n",
      "Running trial 60\n",
      "Running trial 61\n",
      "Running trial 62\n",
      "Running trial 63\n",
      "Running trial 64\n",
      "Running trial 65\n",
      "Running trial 66\n",
      "Running trial 67\n",
      "Running trial 68\n",
      "Running trial 69\n",
      "Running trial 70\n",
      "Running trial 71\n",
      "Running trial 72\n",
      "Running trial 73\n",
      "Running trial 74\n",
      "Running trial 75\n",
      "Running trial 76\n",
      "Running trial 77\n",
      "Running trial 78\n",
      "Running trial 79\n",
      "Running trial 80\n",
      "Running trial 81\n",
      "Running trial 82\n",
      "Running trial 83\n",
      "Running trial 84\n",
      "Running trial 85\n",
      "Running trial 86\n",
      "Running trial 87\n",
      "Running trial 88\n",
      "Running trial 89\n",
      "Running trial 90\n",
      "Running trial 91\n",
      "Running trial 92\n",
      "Running trial 93\n",
      "Running trial 94\n",
      "Running trial 95\n",
      "Running trial 96\n",
      "Running trial 97\n",
      "Running trial 98\n",
      "Running trial 99\n",
      "Running trial 100\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 101\n",
      "Running trial 102\n",
      "Running trial 103\n",
      "Running trial 104\n",
      "Running trial 105\n",
      "Running trial 106\n",
      "Running trial 107\n",
      "Running trial 108\n",
      "Running trial 109\n",
      "Running trial 110\n",
      "Running trial 111\n",
      "Running trial 112\n",
      "Running trial 113\n",
      "Running trial 114\n",
      "Running trial 115\n",
      "Running trial 116\n",
      "Running trial 117\n",
      "Running trial 118\n",
      "Running trial 119\n",
      "Running trial 120\n",
      "Running trial 121\n",
      "Running trial 122\n",
      "Running trial 123\n",
      "Running trial 124\n",
      "Running trial 125\n",
      "Running trial 126\n",
      "Running trial 127\n",
      "Running trial 128\n",
      "Running trial 129\n",
      "Running trial 130\n",
      "Running trial 131\n",
      "Running trial 132\n",
      "Running trial 133\n",
      "Running trial 134\n",
      "Running trial 135\n",
      "Running trial 136\n",
      "Running trial 137\n",
      "Running trial 138\n",
      "Running trial 139\n",
      "Running trial 140\n",
      "Running trial 141\n",
      "Running trial 142\n",
      "Running trial 143\n",
      "Running trial 144\n",
      "Running trial 145\n",
      "Running trial 146\n",
      "Running trial 147\n",
      "Running trial 148\n",
      "Running trial 149\n",
      "Running trial 150\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 151\n",
      "Running trial 152\n",
      "Running trial 153\n",
      "Running trial 154\n",
      "Running trial 155\n",
      "Running trial 156\n",
      "Running trial 157\n",
      "Running trial 158\n",
      "Running trial 159\n",
      "Running trial 160\n",
      "Running trial 161\n",
      "Running trial 162\n",
      "Running trial 163\n",
      "Running trial 164\n",
      "Running trial 165\n",
      "Running trial 166\n",
      "Running trial 167\n",
      "Running trial 168\n",
      "Running trial 169\n",
      "Running trial 170\n",
      "Running trial 171\n",
      "Running trial 172\n",
      "Running trial 173\n",
      "Running trial 174\n",
      "Running trial 175\n",
      "Running trial 176\n",
      "Running trial 177\n",
      "Running trial 178\n",
      "Running trial 179\n",
      "Running trial 180\n",
      "Running trial 181\n",
      "Running trial 182\n",
      "Running trial 183\n",
      "Running trial 184\n",
      "Running trial 185\n",
      "Running trial 186\n",
      "Running trial 187\n",
      "Running trial 188\n",
      "Running trial 189\n",
      "Running trial 190\n",
      "Running trial 191\n",
      "Running trial 192\n",
      "Running trial 193\n",
      "Running trial 194\n",
      "Running trial 195\n",
      "Running trial 196\n",
      "Running trial 197\n",
      "Running trial 198\n",
      "Running trial 199\n",
      "Running trial 200\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 201\n",
      "Running trial 202\n",
      "Running trial 203\n",
      "Running trial 204\n",
      "Running trial 205\n",
      "Running trial 206\n",
      "Running trial 207\n",
      "Running trial 208\n",
      "Running trial 209\n",
      "Running trial 210\n",
      "Running trial 211\n",
      "Running trial 212\n",
      "Running trial 213\n",
      "Running trial 214\n",
      "Running trial 215\n",
      "Running trial 216\n",
      "Running trial 217\n",
      "Running trial 218\n",
      "Running trial 219\n",
      "Running trial 220\n",
      "Running trial 221\n",
      "Running trial 222\n",
      "Running trial 223\n",
      "Running trial 224\n",
      "Running trial 225\n",
      "Running trial 226\n",
      "Running trial 227\n",
      "Running trial 228\n",
      "Running trial 229\n",
      "Running trial 230\n",
      "Running trial 231\n",
      "Running trial 232\n",
      "Running trial 233\n",
      "Running trial 234\n",
      "Running trial 235\n",
      "Running trial 236\n",
      "Running trial 237\n",
      "Running trial 238\n",
      "Running trial 239\n",
      "Running trial 240\n",
      "Running trial 241\n",
      "Running trial 242\n",
      "Running trial 243\n",
      "Running trial 244\n",
      "Running trial 245\n",
      "Running trial 246\n",
      "Running trial 247\n",
      "Running trial 248\n",
      "Running trial 249\n",
      "Running trial 250\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 251\n",
      "Running trial 252\n",
      "Running trial 253\n",
      "Running trial 254\n",
      "Running trial 255\n",
      "Running trial 256\n",
      "Running trial 257\n",
      "Running trial 258\n",
      "Running trial 259\n",
      "Running trial 260\n",
      "Running trial 261\n",
      "Running trial 262\n",
      "Running trial 263\n",
      "Running trial 264\n",
      "Running trial 265\n",
      "Running trial 266\n",
      "Running trial 267\n",
      "Running trial 268\n",
      "Running trial 269\n",
      "Running trial 270\n",
      "Running trial 271\n",
      "Running trial 272\n",
      "Running trial 273\n",
      "Running trial 274\n",
      "Running trial 275\n",
      "Running trial 276\n",
      "Running trial 277\n",
      "Running trial 278\n",
      "Running trial 279\n",
      "Running trial 280\n",
      "Running trial 281\n",
      "Running trial 282\n",
      "Running trial 283\n",
      "Running trial 284\n",
      "Running trial 285\n",
      "Running trial 286\n",
      "Running trial 287\n",
      "Running trial 288\n",
      "Running trial 289\n",
      "Running trial 290\n",
      "Running trial 291\n",
      "Running trial 292\n",
      "Running trial 293\n",
      "Running trial 294\n",
      "Running trial 295\n",
      "Running trial 296\n",
      "Running trial 297\n",
      "Running trial 298\n",
      "Running trial 299\n",
      "Running trial 300\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 301\n",
      "Running trial 302\n",
      "Running trial 303\n",
      "Running trial 304\n",
      "Running trial 305\n",
      "Running trial 306\n",
      "Running trial 307\n",
      "Running trial 308\n",
      "Running trial 309\n",
      "Running trial 310\n",
      "Running trial 311\n",
      "Running trial 312\n",
      "Running trial 313\n",
      "Running trial 314\n",
      "Running trial 315\n",
      "Running trial 316\n",
      "Running trial 317\n",
      "Running trial 318\n",
      "Running trial 319\n",
      "Running trial 320\n",
      "Running trial 321\n",
      "Running trial 322\n",
      "Running trial 323\n",
      "Running trial 324\n",
      "Running trial 325\n",
      "Running trial 326\n",
      "Running trial 327\n",
      "Running trial 328\n",
      "Running trial 329\n",
      "Running trial 330\n",
      "Running trial 331\n",
      "Running trial 332\n",
      "Running trial 333\n",
      "Running trial 334\n",
      "Running trial 335\n",
      "Running trial 336\n",
      "Running trial 337\n",
      "Running trial 338\n",
      "Running trial 339\n",
      "Running trial 340\n",
      "Running trial 341\n",
      "Running trial 342\n",
      "Running trial 343\n",
      "Running trial 344\n",
      "Running trial 345\n",
      "Running trial 346\n",
      "Running trial 347\n",
      "Running trial 348\n",
      "Running trial 349\n",
      "Running trial 350\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 351\n",
      "Running trial 352\n",
      "Running trial 353\n",
      "Running trial 354\n",
      "Running trial 355\n",
      "Running trial 356\n",
      "Running trial 357\n",
      "Running trial 358\n",
      "Running trial 359\n",
      "Running trial 360\n",
      "Running trial 361\n",
      "Running trial 362\n",
      "Running trial 363\n",
      "Running trial 364\n",
      "Running trial 365\n",
      "Running trial 366\n",
      "Running trial 367\n",
      "Running trial 368\n",
      "Running trial 369\n",
      "Running trial 370\n",
      "Running trial 371\n",
      "Running trial 372\n",
      "Running trial 373\n",
      "Running trial 374\n",
      "Running trial 375\n",
      "Running trial 376\n",
      "Running trial 377\n",
      "Running trial 378\n",
      "Running trial 379\n",
      "Running trial 380\n",
      "Running trial 381\n",
      "Running trial 382\n",
      "Running trial 383\n",
      "Running trial 384\n",
      "Running trial 385\n",
      "Running trial 386\n",
      "Running trial 387\n",
      "Running trial 388\n",
      "Running trial 389\n",
      "Running trial 390\n",
      "Running trial 391\n",
      "Running trial 392\n",
      "Running trial 393\n",
      "Running trial 394\n",
      "Running trial 395\n",
      "Running trial 396\n",
      "Running trial 397\n",
      "Running trial 398\n",
      "Running trial 399\n",
      "Running trial 400\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 401\n",
      "Running trial 402\n",
      "Running trial 403\n",
      "Running trial 404\n",
      "Running trial 405\n",
      "Running trial 406\n",
      "Running trial 407\n",
      "Running trial 408\n",
      "Running trial 409\n",
      "Running trial 410\n",
      "Running trial 411\n",
      "Running trial 412\n",
      "Running trial 413\n",
      "Running trial 414\n",
      "Running trial 415\n",
      "Running trial 416\n",
      "Running trial 417\n",
      "Running trial 418\n",
      "Running trial 419\n",
      "Running trial 420\n",
      "Running trial 421\n",
      "Running trial 422\n",
      "Running trial 423\n",
      "Running trial 424\n",
      "Running trial 425\n",
      "Running trial 426\n",
      "Running trial 427\n",
      "Running trial 428\n",
      "Running trial 429\n",
      "Running trial 430\n",
      "Running trial 431\n",
      "Running trial 432\n",
      "Running trial 433\n",
      "Running trial 434\n",
      "Running trial 435\n",
      "Running trial 436\n",
      "Running trial 437\n",
      "Running trial 438\n",
      "Running trial 439\n",
      "Running trial 440\n",
      "Running trial 441\n",
      "Running trial 442\n",
      "Running trial 443\n",
      "Running trial 444\n",
      "Running trial 445\n",
      "Running trial 446\n",
      "Running trial 447\n",
      "Running trial 448\n",
      "Running trial 449\n",
      "Running trial 450\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 451\n",
      "Running trial 452\n",
      "Running trial 453\n",
      "Running trial 454\n",
      "Running trial 455\n",
      "Running trial 456\n",
      "Running trial 457\n",
      "Running trial 458\n",
      "Running trial 459\n",
      "Running trial 460\n",
      "Running trial 461\n",
      "Running trial 462\n",
      "Running trial 463\n",
      "Running trial 464\n",
      "Running trial 465\n",
      "Running trial 466\n",
      "Running trial 467\n",
      "Running trial 468\n",
      "Running trial 469\n",
      "Running trial 470\n",
      "Running trial 471\n",
      "Running trial 472\n",
      "Running trial 473\n",
      "Running trial 474\n",
      "Running trial 475\n",
      "Running trial 476\n",
      "Running trial 477\n",
      "Running trial 478\n",
      "Running trial 479\n",
      "Running trial 480\n",
      "Running trial 481\n",
      "Running trial 482\n",
      "Running trial 483\n",
      "Running trial 484\n",
      "Running trial 485\n",
      "Running trial 486\n",
      "Running trial 487\n",
      "Running trial 488\n",
      "Running trial 489\n",
      "Running trial 490\n",
      "Running trial 491\n",
      "Running trial 492\n",
      "Running trial 493\n",
      "Running trial 494\n",
      "Running trial 495\n",
      "Running trial 496\n",
      "Running trial 497\n",
      "Running trial 498\n",
      "Running trial 499\n",
      "Running trial 500\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 501\n",
      "Running trial 502\n",
      "Running trial 503\n",
      "Running trial 504\n",
      "Running trial 505\n",
      "Running trial 506\n",
      "Running trial 507\n",
      "Running trial 508\n",
      "Running trial 509\n",
      "Running trial 510\n",
      "Running trial 511\n",
      "Running trial 512\n",
      "Running trial 513\n",
      "Running trial 514\n",
      "Running trial 515\n",
      "Running trial 516\n",
      "Running trial 517\n",
      "Running trial 518\n",
      "Running trial 519\n",
      "Running trial 520\n",
      "Running trial 521\n",
      "Running trial 522\n",
      "Running trial 523\n",
      "Running trial 524\n",
      "Running trial 525\n",
      "Running trial 526\n",
      "Running trial 527\n",
      "Running trial 528\n",
      "Running trial 529\n",
      "Running trial 530\n",
      "Running trial 531\n",
      "Running trial 532\n",
      "Running trial 533\n",
      "Running trial 534\n",
      "Running trial 535\n",
      "Running trial 536\n",
      "Running trial 537\n",
      "Running trial 538\n",
      "Running trial 539\n",
      "Running trial 540\n",
      "Running trial 541\n",
      "Running trial 542\n",
      "Running trial 543\n",
      "Running trial 544\n",
      "Running trial 545\n",
      "Running trial 546\n",
      "Running trial 547\n",
      "Running trial 548\n",
      "Running trial 549\n",
      "Running trial 550\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 551\n",
      "Running trial 552\n",
      "Running trial 553\n",
      "Running trial 554\n",
      "Running trial 555\n",
      "Running trial 556\n",
      "Running trial 557\n",
      "Running trial 558\n",
      "Running trial 559\n",
      "Running trial 560\n",
      "Running trial 561\n",
      "Running trial 562\n",
      "Running trial 563\n",
      "Running trial 564\n",
      "Running trial 565\n",
      "Running trial 566\n",
      "Running trial 567\n",
      "Running trial 568\n",
      "Running trial 569\n",
      "Running trial 570\n",
      "Running trial 571\n",
      "Running trial 572\n",
      "Running trial 573\n",
      "Running trial 574\n",
      "Running trial 575\n",
      "Running trial 576\n",
      "Running trial 577\n",
      "Running trial 578\n",
      "Running trial 579\n",
      "Running trial 580\n",
      "Running trial 581\n",
      "Running trial 582\n",
      "Running trial 583\n",
      "Running trial 584\n",
      "Running trial 585\n",
      "Running trial 586\n",
      "Running trial 587\n",
      "Running trial 588\n",
      "Running trial 589\n",
      "Running trial 590\n",
      "Running trial 591\n",
      "Running trial 592\n",
      "Running trial 593\n",
      "Running trial 594\n",
      "Running trial 595\n",
      "Running trial 596\n",
      "Running trial 597\n",
      "Running trial 598\n",
      "Running trial 599\n",
      "Running trial 600\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 601\n",
      "Running trial 602\n",
      "Running trial 603\n",
      "Running trial 604\n",
      "Running trial 605\n",
      "Running trial 606\n",
      "Running trial 607\n",
      "Running trial 608\n",
      "Running trial 609\n",
      "Running trial 610\n",
      "Running trial 611\n",
      "Running trial 612\n",
      "Running trial 613\n",
      "Running trial 614\n",
      "Running trial 615\n",
      "Running trial 616\n",
      "Running trial 617\n",
      "Running trial 618\n",
      "Running trial 619\n",
      "Running trial 620\n",
      "Running trial 621\n",
      "Running trial 622\n",
      "Running trial 623\n",
      "Running trial 624\n",
      "Running trial 625\n",
      "Running trial 626\n",
      "Running trial 627\n",
      "Running trial 628\n",
      "Running trial 629\n",
      "Running trial 630\n",
      "Running trial 631\n",
      "Running trial 632\n",
      "Running trial 633\n",
      "Running trial 634\n",
      "Running trial 635\n",
      "Running trial 636\n",
      "Running trial 637\n",
      "Running trial 638\n",
      "Running trial 639\n",
      "Running trial 640\n",
      "Running trial 641\n",
      "Running trial 642\n",
      "Running trial 643\n",
      "Running trial 644\n",
      "Running trial 645\n",
      "Running trial 646\n",
      "Running trial 647\n",
      "Running trial 648\n",
      "Running trial 649\n",
      "Running trial 650\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 651\n",
      "Running trial 652\n",
      "Running trial 653\n",
      "Running trial 654\n",
      "Running trial 655\n",
      "Running trial 656\n",
      "Running trial 657\n",
      "Running trial 658\n",
      "Running trial 659\n",
      "Running trial 660\n",
      "Running trial 661\n",
      "Running trial 662\n",
      "Running trial 663\n",
      "Running trial 664\n",
      "Running trial 665\n",
      "Running trial 666\n",
      "Running trial 667\n",
      "Running trial 668\n",
      "Running trial 669\n",
      "Running trial 670\n",
      "Running trial 671\n",
      "Running trial 672\n",
      "Running trial 673\n",
      "Running trial 674\n",
      "Running trial 675\n",
      "Running trial 676\n",
      "Running trial 677\n",
      "Running trial 678\n",
      "Running trial 679\n",
      "Running trial 680\n",
      "Running trial 681\n",
      "Running trial 682\n",
      "Running trial 683\n",
      "Running trial 684\n",
      "Running trial 685\n",
      "Running trial 686\n",
      "Running trial 687\n",
      "Running trial 688\n",
      "Running trial 689\n",
      "Running trial 690\n",
      "Running trial 691\n",
      "Running trial 692\n",
      "Running trial 693\n",
      "Running trial 694\n",
      "Running trial 695\n",
      "Running trial 696\n",
      "Running trial 697\n",
      "Running trial 698\n",
      "Running trial 699\n",
      "Running trial 700\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 701\n",
      "Running trial 702\n",
      "Running trial 703\n",
      "Running trial 704\n",
      "Running trial 705\n",
      "Running trial 706\n",
      "Running trial 707\n",
      "Running trial 708\n",
      "Running trial 709\n",
      "Running trial 710\n",
      "Running trial 711\n",
      "Running trial 712\n",
      "Running trial 713\n",
      "Running trial 714\n",
      "Running trial 715\n",
      "Running trial 716\n",
      "Running trial 717\n",
      "Running trial 718\n",
      "Running trial 719\n",
      "Running trial 720\n",
      "Running trial 721\n",
      "Running trial 722\n",
      "Running trial 723\n",
      "Running trial 724\n",
      "Running trial 725\n",
      "Running trial 726\n",
      "Running trial 727\n",
      "Running trial 728\n",
      "Running trial 729\n",
      "Running trial 730\n",
      "Running trial 731\n",
      "Running trial 732\n",
      "Running trial 733\n",
      "Running trial 734\n",
      "Running trial 735\n",
      "Running trial 736\n",
      "Running trial 737\n",
      "Running trial 738\n",
      "Running trial 739\n",
      "Running trial 740\n",
      "Running trial 741\n",
      "Running trial 742\n",
      "Running trial 743\n",
      "Running trial 744\n",
      "Running trial 745\n",
      "Running trial 746\n",
      "Running trial 747\n",
      "Running trial 748\n",
      "Running trial 749\n",
      "Running trial 750\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 751\n",
      "Running trial 752\n",
      "Running trial 753\n",
      "Running trial 754\n",
      "Running trial 755\n",
      "Running trial 756\n",
      "Running trial 757\n",
      "Running trial 758\n",
      "Running trial 759\n",
      "Running trial 760\n",
      "Running trial 761\n",
      "Running trial 762\n",
      "Running trial 763\n",
      "Running trial 764\n",
      "Running trial 765\n",
      "Running trial 766\n",
      "Running trial 767\n",
      "Running trial 768\n",
      "Running trial 769\n",
      "Running trial 770\n",
      "Running trial 771\n",
      "Running trial 772\n",
      "Running trial 773\n",
      "Running trial 774\n",
      "Running trial 775\n",
      "Running trial 776\n",
      "Running trial 777\n",
      "Running trial 778\n",
      "Running trial 779\n",
      "Running trial 780\n",
      "Running trial 781\n",
      "Running trial 782\n",
      "Running trial 783\n",
      "Running trial 784\n",
      "Running trial 785\n",
      "Running trial 786\n",
      "Running trial 787\n",
      "Running trial 788\n",
      "Running trial 789\n",
      "Running trial 790\n",
      "Running trial 791\n",
      "Running trial 792\n",
      "Running trial 793\n",
      "Running trial 794\n",
      "Running trial 795\n",
      "Running trial 796\n",
      "Running trial 797\n",
      "Running trial 798\n",
      "Running trial 799\n",
      "Running trial 800\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 801\n",
      "Running trial 802\n",
      "Running trial 803\n",
      "Running trial 804\n",
      "Running trial 805\n",
      "Running trial 806\n",
      "Running trial 807\n",
      "Running trial 808\n",
      "Running trial 809\n",
      "Running trial 810\n",
      "Running trial 811\n",
      "Running trial 812\n",
      "Running trial 813\n",
      "Running trial 814\n",
      "Running trial 815\n",
      "Running trial 816\n",
      "Running trial 817\n",
      "Running trial 818\n",
      "Running trial 819\n",
      "Running trial 820\n",
      "Running trial 821\n",
      "Running trial 822\n",
      "Running trial 823\n",
      "Running trial 824\n",
      "Running trial 825\n",
      "Running trial 826\n",
      "Running trial 827\n",
      "Running trial 828\n",
      "Running trial 829\n",
      "Running trial 830\n",
      "Running trial 831\n",
      "Running trial 832\n",
      "Running trial 833\n",
      "Running trial 834\n",
      "Running trial 835\n",
      "Running trial 836\n",
      "Running trial 837\n",
      "Running trial 838\n",
      "Running trial 839\n",
      "Running trial 840\n",
      "Running trial 841\n",
      "Running trial 842\n",
      "Running trial 843\n",
      "Running trial 844\n",
      "Running trial 845\n",
      "Running trial 846\n",
      "Running trial 847\n",
      "Running trial 848\n",
      "Running trial 849\n",
      "Running trial 850\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 851\n",
      "Running trial 852\n",
      "Running trial 853\n",
      "Running trial 854\n",
      "Running trial 855\n",
      "Running trial 856\n",
      "Running trial 857\n",
      "Running trial 858\n",
      "Running trial 859\n",
      "Running trial 860\n",
      "Running trial 861\n",
      "Running trial 862\n",
      "Running trial 863\n",
      "Running trial 864\n",
      "Running trial 865\n",
      "Running trial 866\n",
      "Running trial 867\n",
      "Running trial 868\n",
      "Running trial 869\n",
      "Running trial 870\n",
      "Running trial 871\n",
      "Running trial 872\n",
      "Running trial 873\n",
      "Running trial 874\n",
      "Running trial 875\n",
      "Running trial 876\n",
      "Running trial 877\n",
      "Running trial 878\n",
      "Running trial 879\n",
      "Running trial 880\n",
      "Running trial 881\n",
      "Running trial 882\n",
      "Running trial 883\n",
      "Running trial 884\n",
      "Running trial 885\n",
      "Running trial 886\n",
      "Running trial 887\n",
      "Running trial 888\n",
      "Running trial 889\n",
      "Running trial 890\n",
      "Running trial 891\n",
      "Running trial 892\n",
      "Running trial 893\n",
      "Running trial 894\n",
      "Running trial 895\n",
      "Running trial 896\n",
      "Running trial 897\n",
      "Running trial 898\n",
      "Running trial 899\n",
      "Running trial 900\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 901\n",
      "Running trial 902\n",
      "Running trial 903\n",
      "Running trial 904\n",
      "Running trial 905\n",
      "Running trial 906\n",
      "Running trial 907\n",
      "Running trial 908\n",
      "Running trial 909\n",
      "Running trial 910\n",
      "Running trial 911\n",
      "Running trial 912\n",
      "Running trial 913\n",
      "Running trial 914\n",
      "Running trial 915\n",
      "Running trial 916\n",
      "Running trial 917\n",
      "Running trial 918\n",
      "Running trial 919\n",
      "Running trial 920\n",
      "Running trial 921\n",
      "Running trial 922\n",
      "Running trial 923\n",
      "Running trial 924\n",
      "Running trial 925\n",
      "Running trial 926\n",
      "Running trial 927\n",
      "Running trial 928\n",
      "Running trial 929\n",
      "Running trial 930\n",
      "Running trial 931\n",
      "Running trial 932\n",
      "Running trial 933\n",
      "Running trial 934\n",
      "Running trial 935\n",
      "Running trial 936\n",
      "Running trial 937\n",
      "Running trial 938\n",
      "Running trial 939\n",
      "Running trial 940\n",
      "Running trial 941\n",
      "Running trial 942\n",
      "Running trial 943\n",
      "Running trial 944\n",
      "Running trial 945\n",
      "Running trial 946\n",
      "Running trial 947\n",
      "Running trial 948\n",
      "Running trial 949\n",
      "Running trial 950\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "Running trial 951\n",
      "Running trial 952\n",
      "Running trial 953\n",
      "Running trial 954\n",
      "Running trial 955\n",
      "Running trial 956\n",
      "Running trial 957\n",
      "Running trial 958\n",
      "Running trial 959\n",
      "Running trial 960\n",
      "Running trial 961\n",
      "Running trial 962\n",
      "Running trial 963\n",
      "Running trial 964\n",
      "Running trial 965\n",
      "Running trial 966\n",
      "Running trial 967\n",
      "Running trial 968\n",
      "Running trial 969\n",
      "Running trial 970\n",
      "Running trial 971\n",
      "Running trial 972\n",
      "Running trial 973\n",
      "Running trial 974\n",
      "Running trial 975\n",
      "Running trial 976\n",
      "Running trial 977\n",
      "Running trial 978\n",
      "Running trial 979\n",
      "Running trial 980\n",
      "Running trial 981\n",
      "Running trial 982\n",
      "Running trial 983\n",
      "Running trial 984\n",
      "Running trial 985\n",
      "Running trial 986\n",
      "Running trial 987\n",
      "Running trial 988\n",
      "Running trial 989\n",
      "Running trial 990\n",
      "Running trial 991\n",
      "Running trial 992\n",
      "Running trial 993\n",
      "Running trial 994\n",
      "Running trial 995\n",
      "Running trial 996\n",
      "Running trial 997\n",
      "Running trial 998\n",
      "Running trial 999\n",
      "Running trial 1000\n",
      "Saved checkpoint to: C:/Users/BerkayEren/PycharmProjects/rl-learning/ray_results/checkpoints\n",
      "agent_timesteps_total: 3100000\n",
      "connector_metrics:\n",
      "  MeanStdObservationFilterAgentConnector_ms: 0.09268665313720703\n",
      "  ObsPreprocessorConnector_ms: 0.0\n",
      "  StateBufferConnector_ms: 0.013734102249145508\n",
      "  ViewRequirementAgentConnector_ms: 0.17335939407348633\n",
      "counters:\n",
      "  last_target_update_ts: 3099520\n",
      "  num_agent_steps_sampled: 3100000\n",
      "  num_agent_steps_trained: 4958400\n",
      "  num_env_steps_sampled: 3100000\n",
      "  num_env_steps_trained: 4958400\n",
      "  num_target_updates: 6198\n",
      "custom_metrics: {}\n",
      "date: 2024-04-20_11-53-20\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 2.377173993620012\n",
      "episode_reward_mean: 2.1174052491012882\n",
      "episode_reward_min: 1.8567036651225812\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10000\n",
      "hostname: berkayeren\n",
      "info:\n",
      "  last_target_update_ts: 3099520\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 608.6875\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.00032006955007091165\n",
      "        max_q: 2.704190254211426\n",
      "        mean_q: 2.6862449645996094\n",
      "        min_q: 2.6494202613830566\n",
      "      mean_td_error: -0.0001452118158340454\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 32.0\n",
      "      num_grad_updates_lifetime: 50000.0\n",
      "      td_error: [-0.0005698204040527344, -0.005821704864501953, 0.008251667022705078,\n",
      "        0.001935720443725586, 0.0001347064971923828, -0.00027489662170410156, -0.0048635005950927734,\n",
      "        -0.0011832714080810547, 0.0019359588623046875, 0.005066394805908203, -0.0032961368560791016,\n",
      "        0.008250713348388672, 0.0017299652099609375, 0.0019369125366210938, 0.00048351287841796875,\n",
      "        -0.0044612884521484375, -0.007624387741088867, -0.005001544952392578, 0.0017981529235839844,\n",
      "        -0.00709986686706543, 0.0023703575134277344, 0.0004305839538574219, 0.0008630752563476562,\n",
      "        0.003174304962158203, 0.0018782615661621094, 0.0001838207244873047, 0.0007176399230957031,\n",
      "        0.004439353942871094, -0.015814542770385742, -0.004477977752685547, 0.006819963455200195,\n",
      "        0.0034410953521728516]\n",
      "  num_agent_steps_sampled: 3100000\n",
      "  num_agent_steps_trained: 4958400\n",
      "  num_env_steps_sampled: 3100000\n",
      "  num_env_steps_trained: 4958400\n",
      "  num_target_updates: 6198\n",
      "iterations_since_restore: 1000\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 3100000\n",
      "num_agent_steps_trained: 4958400\n",
      "num_env_steps_sampled: 3100000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 187.4750531878327\n",
      "num_env_steps_trained: 4958400\n",
      "num_env_steps_trained_this_iter: 1600\n",
      "num_env_steps_trained_throughput_per_sec: 299.96008510053235\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 0\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 1600\n",
      "perf:\n",
      "  cpu_util_percent: 31.542857142857144\n",
      "  ram_util_percent: 63.5\n",
      "pid: 11852\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 3.3565266235306477\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 9.723917380782932\n",
      "  mean_inference_ms: 3.4361219811551815\n",
      "  mean_raw_obs_processing_ms: 26.88133980651641\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    MeanStdObservationFilterAgentConnector_ms: 0.09268665313720703\n",
      "    ObsPreprocessorConnector_ms: 0.0\n",
      "    StateBufferConnector_ms: 0.013734102249145508\n",
      "    ViewRequirementAgentConnector_ms: 0.17335939407348633\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.377173993620012\n",
      "  episode_reward_mean: 2.1174052491012882\n",
      "  episode_reward_min: 1.8567036651225812\n",
      "  episodes_this_iter: 20\n",
      "  hist_stats:\n",
      "    episode_lengths: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
      "      100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
      "      100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
      "      100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
      "      100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
      "      100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
      "      100, 100, 100, 100, 100, 100, 100, 100]\n",
      "    episode_reward: [2.2252666256158706, 2.1422865740407713, 2.1059720764165055, 2.105931188074724,\n",
      "      2.2657168847759355, 1.9797314390648322, 2.2140099425617756, 2.0247301455015645,\n",
      "      2.162273623259521, 2.0150704962209955, 2.186190118212631, 2.018783042769142,\n",
      "      2.072999226372361, 2.1769926704158578, 2.0464158567149977, 2.0776276616451663,\n",
      "      2.2097595801224506, 1.978745057912635, 2.1793063120411658, 2.1249961674759454,\n",
      "      2.10762965410052, 2.1555327901517387, 2.1186231097729746, 2.2554742606499776,\n",
      "      2.240136303580269, 2.172894754941832, 2.2196614706045925, 1.9817236266271105,\n",
      "      2.059010031663093, 2.0401206086993517, 2.263098901810377, 2.2079639567936056,\n",
      "      2.1178823163413076, 2.1896995975122593, 2.017553928464619, 2.1454781834252534,\n",
      "      2.1904762396512645, 2.18007009754568, 2.238900293391324, 2.153784136133722,\n",
      "      2.1442493355096377, 2.1094261998411032, 2.0924419326585286, 2.038501433571388,\n",
      "      2.199611028007814, 2.0554041877325284, 2.05586906684745, 2.0093934584622466,\n",
      "      2.2535924836730876, 2.2753662598503617, 2.1124023502789164, 2.144209383621158,\n",
      "      2.06188961868364, 2.140383986482909, 2.1735718645006536, 2.0542983057460935,\n",
      "      2.377173993620012, 2.0803852642809235, 2.062650971210433, 2.235942925542537,\n",
      "      2.191911246081471, 2.1765711387275846, 2.0439053496141075, 2.108464719320849,\n",
      "      2.030367508556932, 2.0550117722707832, 2.2140460950202954, 2.097665395105398,\n",
      "      2.1021971988898365, 1.9956029366253853, 2.14586505852964, 2.0678696287214113,\n",
      "      2.0042442732773975, 2.1865008802887584, 2.1379012952713183, 2.212316866921822,\n",
      "      2.252502360464785, 1.9391186437618424, 2.116555463303146, 2.1125674012355193,\n",
      "      2.1936398514343227, 2.0185532872645813, 2.0899084999525366, 2.0604389116156048,\n",
      "      2.166070184573406, 1.8567036651225812, 2.0194395658733835, 2.05969064108963,\n",
      "      2.016792852768665, 1.9953883873371114, 2.2239918852711873, 2.0555358538029314,\n",
      "      2.003151234306085, 2.117372764650861, 1.9582847396578935, 2.1605080703809953,\n",
      "      2.0951485408208144, 2.144132559933955, 2.223888039835428, 2.045417141251443]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 3.3565266235306477\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 9.723917380782932\n",
      "    mean_inference_ms: 3.4361219811551815\n",
      "    mean_raw_obs_processing_ms: 26.88133980651641\n",
      "time_since_restore: 5224.535062551498\n",
      "time_this_iter_s: 5.337158441543579\n",
      "time_total_s: 5224.535062551498\n",
      "timers:\n",
      "  learn_throughput: 1154.809\n",
      "  learn_time_ms: 27.71\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_time_ms: 53.024\n",
      "  synch_weights_time_ms: 0.0\n",
      "  training_iteration_time_ms: 110.829\n",
      "timestamp: 1713603200\n",
      "timesteps_total: 3100000\n",
      "training_iteration: 3100\n",
      "trial_id: default\n",
      "\n",
      "Running trial 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 54\u001B[0m\n\u001B[0;32m     51\u001B[0m     visited_states[env\u001B[38;5;241m.\u001B[39magent_pos] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     53\u001B[0m     \u001B[38;5;66;03m# Render the environment\u001B[39;00m\n\u001B[1;32m---> 54\u001B[0m     \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m all_observations\u001B[38;5;241m.\u001B[39mappend(visited_states)\n",
      "File \u001B[1;32m~\\PycharmProjects\\rl-learning\\worker_env\\lib\\site-packages\\gymnasium\\core.py:418\u001B[0m, in \u001B[0;36mWrapper.render\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    416\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrender\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m RenderFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mlist\u001B[39m[RenderFrame] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    417\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 418\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\rl-learning\\worker_env\\lib\\site-packages\\minigrid\\minigrid_env.py:772\u001B[0m, in \u001B[0;36mMiniGridEnv.render\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    770\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwindow\u001B[38;5;241m.\u001B[39mblit(bg, (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m    771\u001B[0m     pygame\u001B[38;5;241m.\u001B[39mevent\u001B[38;5;241m.\u001B[39mpump()\n\u001B[1;32m--> 772\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtick\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrender_fps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    773\u001B[0m     pygame\u001B[38;5;241m.\u001B[39mdisplay\u001B[38;5;241m.\u001B[39mflip()\n\u001B[0;32m    775\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrender_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrgb_array\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from numpy import inf\n",
    "from minigrid import Wall\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a 2D array representing the environment\n",
    "env_array = np.full((env.width, env.height), 0)  # Use a value of 10 to represent the walls\n",
    "\n",
    "\n",
    "def find_goal_position(env):\n",
    "    for x in range(env.width):\n",
    "        for y in range(env.height):\n",
    "            if env.grid.get(x, y) is not None and env.grid.get(x, y).type == 'goal':\n",
    "                return x, y\n",
    "    return None, None\n",
    "\n",
    "\n",
    "goal_x, goal_y = find_goal_position(env)\n",
    "\n",
    "wall_x = []\n",
    "wall_y = []\n",
    "# Iterate over the cells in the environment\n",
    "for i in range(env.width):\n",
    "    for j in range(env.height):\n",
    "        # If the cell is a wall, set its value in the array to a high value (e.g., 10)\n",
    "        if isinstance(env.grid.get(i, j), Wall):\n",
    "            env_array[i, j] = 10\n",
    "            wall_x.append(i)\n",
    "            wall_y.append(j)\n",
    "\n",
    "# Generate and save a heatmap for each trial\n",
    "for i, trial_observations in enumerate(all_observations):\n",
    "    visited_states_array = np.zeros((env.width, env.height))\n",
    "\n",
    "    # Iterate over the visited states\n",
    "    for position, count in trial_observations.items():\n",
    "        # Set the value at the agent's position in the array to the visit count\n",
    "        visited_states_array[position] = count\n",
    "\n",
    "    # Overlay the visited states array on the environment array\n",
    "    heatmap_array = env_array + visited_states_array\n",
    "    # Generate the heatmap\n",
    "    plt.imshow(heatmap_array, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(wall_x, wall_y, c='white', marker='s', s=100)\n",
    "    plt.scatter(goal_x, goal_y, c='green', marker='*', s=200)\n",
    "    plt.title(f'Heatmap of Visited States in Trial {i + 1}')\n",
    "\n",
    "    date_string = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Save the heatmap to a file\n",
    "    plt.savefig(f'heatmaps/heatmap_dowham_trial_{i + 1}_{date_string}.png')\n",
    "\n",
    "    # Clear the current figure so the next heatmap doesn't overlap with this one\n",
    "    plt.clf()"
   ],
   "id": "8573a6264f19de01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1c437967e49cba8e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
