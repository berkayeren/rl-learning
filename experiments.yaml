base_config:
  # Anything here is shared across *all* variations,
  # unless it's overridden below.
  env_config:
    enable_dowham_reward_v1: false
    enable_dowham_reward_v2: false
    enable_count_based: false
    enable_rnd: false
  model:
    fcnet_activation: relu
    post_fcnet_activation: relu
    fcnet_hiddens: [ 256, 256 ]
  train_batch_size: 256
  rollout_fragment_length: 256

variations:
  # -----------------------------------------------------
  # DoWhaM v1 (enable_dowham_reward_v1 = true)
  # -----------------------------------------------------
  # - name: DoWhaM_v1_batch32
  #   env_config:
  #     enable_dowham_reward_v1: true
  #     enable_dowham_reward_v2: false
  #   model:
  #     fcnet_hiddens: [ 256, 128 ]
  #   train_batch_size: 32
  #   rollout_fragment_length: 32

  # -----------------------------------------------------
  # DoWhaM v2 (enable_dowham_reward_v2 = true)
  # -----------------------------------------------------
  - name: combination_relu_relu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: relu
        activation_fn_value_name: relu

  - name: combination_relu_elu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: relu
        activation_fn_value_name: elu

  - name: combination_relu_leaky_relu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: relu
        activation_fn_value_name: leaky_relu

  - name: combination_relu_tanh
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: relu
        activation_fn_value_name: tanh

  - name: combination_relu_sigmoid
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: relu
        activation_fn_value_name: sigmoid

  - name: combination_relu_softplus
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: relu
        activation_fn_value_name: softplus

  - name: combination_elu_relu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: elu
        activation_fn_value_name: relu

  - name: combination_elu_elu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: elu
        activation_fn_value_name: elu

  - name: combination_elu_leaky_relu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: elu
        activation_fn_value_name: leaky_relu

  - name: combination_elu_tanh
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: elu
        activation_fn_value_name: tanh

  - name: combination_elu_sigmoid
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: elu
        activation_fn_value_name: sigmoid

  - name: combination_elu_softplus
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: elu
        activation_fn_value_name: softplus

  - name: combination_leaky_relu_relu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: leaky_relu
        activation_fn_value_name: relu

  - name: combination_leaky_relu_elu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: leaky_relu
        activation_fn_value_name: elu

  - name: combination_leaky_relu_leaky_relu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: leaky_relu
        activation_fn_value_name: leaky_relu

  - name: combination_leaky_relu_tanh
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: leaky_relu
        activation_fn_value_name: tanh

  - name: combination_leaky_relu_sigmoid
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: leaky_relu
        activation_fn_value_name: sigmoid

  - name: combination_leaky_relu_softplus
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: leaky_relu
        activation_fn_value_name: softplus

  - name: combination_tanh_relu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: tanh
        activation_fn_value_name: relu

  - name: combination_tanh_elu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: tanh
        activation_fn_value_name: elu

  - name: combination_tanh_leaky_relu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: tanh
        activation_fn_value_name: leaky_relu

  - name: combination_tanh_tanh
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: tanh
        activation_fn_value_name: tanh

  - name: combination_tanh_sigmoid
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: tanh
        activation_fn_value_name: sigmoid

  - name: combination_tanh_softplus
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: tanh
        activation_fn_value_name: softplus

  - name: combination_sigmoid_relu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: sigmoid
        activation_fn_value_name: relu

  - name: combination_sigmoid_elu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: sigmoid
        activation_fn_value_name: elu

  - name: combination_sigmoid_leaky_relu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: sigmoid
        activation_fn_value_name: leaky_relu

  - name: combination_sigmoid_tanh
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: sigmoid
        activation_fn_value_name: tanh

  - name: combination_sigmoid_sigmoid
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: sigmoid
        activation_fn_value_name: sigmoid

  - name: combination_sigmoid_softplus
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: sigmoid
        activation_fn_value_name: softplus

  - name: combination_softplus_relu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: softplus
        activation_fn_value_name: relu

  - name: combination_softplus_elu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: softplus
        activation_fn_value_name: elu

  - name: combination_softplus_leaky_relu
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: softplus
        activation_fn_value_name: leaky_relu

  - name: combination_softplus_tanh
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: softplus
        activation_fn_value_name: tanh

  - name: combination_softplus_sigmoid
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: softplus
        activation_fn_value_name: sigmoid

  - name: combination_softplus_softplus
    env_config:
      enable_dowham_reward_v1: false
      enable_dowham_reward_v2: true
      max_steps: 200
      transition_divisor: 10
    model:
      custom_model_config:
        custom_activation: softplus
        activation_fn_value_name: softplus

  #  # -----------------------------------------------------
  #  # RND
  #  # -----------------------------------------------------
  #  - name: RND
  #    env_config:
  #      enable_rnd: true
  #      enable_count_based: false
  #      enable_dowham_reward_v1: false
  #      enable_dowham_reward_v2: false
  #    train_batch_size: 32
  #    rollout_fragment_length: 32
  #
  #  # -----------------------------------------------------
  #  # CountBased
  #  # -----------------------------------------------------
  #  - name: CountBased
  #    env_config:
  #      enable_count_based: true
  #      enable_rnd: false
  #      enable_dowham_reward_v1: false
  #      enable_dowham_reward_v2: false
  #    train_batch_size: 32
  #    rollout_fragment_length: 32
  #
  # -----------------------------------------------------
  # Default (no intrinsic rewards)
  # -----------------------------------------------------
#  - name: Default
#    env_config:
#      enable_dowham_reward_v1: false
#      enable_dowham_reward_v2: false
#      enable_count_based: false
#      enable_rnd: false
#    train_batch_size: 128
#    rollout_fragment_length: 64
#    batch_mode: complete_episodes
#    exploration_config:
#      epsilon_schedule:
#        endpoints: [ (0, 1), (100000, 0.5), (500000, 0.1 ) ]